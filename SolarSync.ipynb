{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SolarSync Predictor\n",
        "\n",
        "*   Using historical solar production and weather sensor data (e.g., irradiance, temperature) to optimize grid stability. It\n",
        "leverages time-series Supervised machine learning models and a Dash dashboard for real-time visualization using XGBoost and LSTM\n",
        "\n"
      ],
      "metadata": {
        "id": "69teG_jec5sB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.model_selection import TimeSeriesSplit, train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "from xgboost import XGBRegressor, plot_importance\n",
        "\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n"
      ],
      "metadata": {
        "id": "MMzzav5octTQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üóÇÔ∏è Data Cleaning & Merging\n",
        "\n",
        "def load_data(gen_path, weather_path):\n",
        "    gen_df = pd.read_csv(gen_path, parse_dates=['DATE_TIME'])\n",
        "    weather_df = pd.read_csv(weather_path, parse_dates=['DATE_TIME'])\n",
        "    return gen_df, weather_df\n",
        "\n",
        "def clean_data(gen_df, weather_df):\n",
        "    gen_df = gen_df[gen_df['PLANT_ID'] == 4135001]\n",
        "    weather_df = weather_df[weather_df['PLANT_ID'] == 4135001]\n",
        "\n",
        "    gen_df.fillna({'DC_POWER': 0, 'AC_POWER': 0, 'DAILY_YIELD': 0, 'TOTAL_YIELD': 0}, inplace=True)\n",
        "    weather_df.fillna(method='ffill', inplace=True)\n",
        "\n",
        "    gen_df['DATE_TIME'] = gen_df['DATE_TIME'].dt.floor('H')\n",
        "    gen_df = gen_df.groupby(['DATE_TIME', 'PLANT_ID']).agg({\n",
        "        'DC_POWER': 'mean',\n",
        "        'AC_POWER': 'mean',\n",
        "        'DAILY_YIELD': 'mean',\n",
        "        'TOTAL_YIELD': 'mean'\n",
        "    }).reset_index()\n",
        "\n",
        "    weather_df['DATE_TIME'] = weather_df['DATE_TIME'].dt.floor('H')\n",
        "    weather_df = weather_df.groupby(['DATE_TIME', 'PLANT_ID']).agg({\n",
        "        'AMBIENT_TEMPERATURE': 'mean',\n",
        "        'MODULE_TEMPERATURE': 'mean',\n",
        "        'IRRADIATION': 'mean'\n",
        "    }).reset_index()\n",
        "\n",
        "    merged_df = pd.merge(gen_df, weather_df, on=['DATE_TIME', 'PLANT_ID'], how='inner')\n",
        "    merged_df.drop_duplicates(subset=['DATE_TIME', 'PLANT_ID'], inplace=True)\n",
        "\n",
        "    return merged_df\n",
        "\n",
        "# Example execution\n",
        "gen_df, weather_df = load_data('Generation_Data.csv', 'Weather_Sensor_Data.csv')\n",
        "cleaned_df = clean_data(gen_df, weather_df)\n",
        "cleaned_df.to_csv('cleaned_solar_data.csv', index=False)\n",
        "print(\"Cleaned dataset saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yI5Stwkc2DR",
        "outputId": "d321290a-4a21-4d2a-8794-c44d7036b2ba"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned dataset saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üõ†Ô∏è Feature Engineering & Preprocessing\n",
        "\n",
        "def engineer_features(df):\n",
        "    df['hour'] = df.index.hour\n",
        "    df['day'] = df.index.day\n",
        "    df['month'] = df.index.month\n",
        "    df['day_of_week'] = df.index.dayofweek\n",
        "\n",
        "    df['ac_power_lag1'] = df['AC_POWER'].shift(1)\n",
        "    df['irradiation_lag1'] = df['IRRADIATION'].shift(1)\n",
        "\n",
        "    df['ac_power_rolling_mean'] = df['AC_POWER'].rolling(window=3).mean()\n",
        "    df['irradiation_rolling_mean'] = df['IRRADIATION'].rolling(window=3).mean()\n",
        "\n",
        "    df.fillna(method='ffill', inplace=True)\n",
        "    df.fillna(method='bfill', inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "def normalize_features(df, feature_cols):\n",
        "    scaler = MinMaxScaler()\n",
        "    df[feature_cols] = scaler.fit_transform(df[feature_cols])\n",
        "    return df, scaler\n",
        "\n",
        "def prepare_lstm_data(X, y, time_steps=10):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        Xs.append(X[i:(i + time_steps)])\n",
        "        ys.append(y[i + time_steps])\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "def preprocess_data(file_path):\n",
        "    df = pd.read_csv(file_path, parse_dates=['DATE_TIME'])\n",
        "    df.set_index('DATE_TIME', inplace=True)\n",
        "    df = engineer_features(df)\n",
        "\n",
        "    feature_cols = [\n",
        "        'IRRADIATION', 'AMBIENT_TEMPERATURE', 'MODULE_TEMPERATURE',\n",
        "        'hour', 'day', 'month', 'day_of_week',\n",
        "        'ac_power_lag1', 'irradiation_lag1',\n",
        "        'ac_power_rolling_mean', 'irradiation_rolling_mean'\n",
        "    ]\n",
        "\n",
        "    target_col = 'AC_POWER'\n",
        "    df, scaler = normalize_features(df, feature_cols)\n",
        "\n",
        "    X = df[feature_cols].values\n",
        "    y = df[target_col].values\n",
        "\n",
        "    X_lstm, y_lstm = prepare_lstm_data(X, y)\n",
        "\n",
        "    pd.DataFrame(X, columns=feature_cols, index=df.index[:len(X)]).to_csv('X_tabular.csv')\n",
        "    pd.DataFrame(y, columns=[target_col], index=df.index[:len(y)]).to_csv('y_tabular.csv')\n",
        "    np.save('X_lstm.npy', X_lstm)\n",
        "    np.save('y_lstm.npy', y_lstm)\n",
        "    joblib.dump(scaler, 'scaler.pkl')\n",
        "\n",
        "    return X, y, X_lstm, y_lstm, scaler, feature_cols\n",
        "\n",
        "# Example execution\n",
        "X, y, X_lstm, y_lstm, scaler, feature_cols = preprocess_data('cleaned_solar_data.csv')\n",
        "print(\"Preprocessing completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRZ34S_5dtLa",
        "outputId": "dcdb1407-e54f-4698-9183-a18d72bb0bd0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ü§ñ Model Training & Saving\n",
        "\n",
        "def evaluate_model(y_true, y_pred, model_name):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    print(f\"{model_name} - MAE: {mae:.4f}, RMSE: {rmse:.4f}, R¬≤: {r2:.4f}\")\n",
        "    return mae, rmse, r2\n",
        "\n",
        "def train_models(X_tabular, y_tabular, X_lstm, y_lstm):\n",
        "    tscv = TimeSeriesSplit(n_splits=5)\n",
        "    results = {'LinearRegression': [], 'XGBoost': [], 'LSTM': []}\n",
        "\n",
        "    # Linear Regression\n",
        "    print(\"\\nTraining Linear Regression...\")\n",
        "    lr_model = LinearRegression()\n",
        "    for fold, (train_idx, test_idx) in enumerate(tscv.split(X_tabular)):\n",
        "        X_train, X_test = X_tabular[train_idx], X_tabular[test_idx]\n",
        "        y_train, y_test = y_tabular[train_idx], y_tabular[test_idx]\n",
        "        lr_model.fit(X_train, y_train)\n",
        "        evaluate_model(y_test, lr_model.predict(X_test), f\"Linear Regression (Fold {fold+1})\")\n",
        "    joblib.dump(lr_model, 'lr_model.pkl')\n",
        "    print(\"Linear Regression model saved as 'lr_model.pkl'\")\n",
        "\n",
        "\n",
        "    # XGBoost\n",
        "    print(\"\\nTraining XGBoost...\")\n",
        "    xgb_model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42)\n",
        "    for fold, (train_idx, test_idx) in enumerate(tscv.split(X_tabular)):\n",
        "        X_train, X_test = X_tabular[train_idx], X_tabular[test_idx]\n",
        "        y_train, y_test = y_tabular[train_idx], y_tabular[test_idx]\n",
        "        xgb_model.fit(X_train, y_train)\n",
        "        evaluate_model(y_test, xgb_model.predict(X_test), f\"XGBoost (Fold {fold+1})\")\n",
        "    joblib.dump(xgb_model, 'xgb_model.pkl')\n",
        "    print(\"XGBoost model saved as 'xgb_model.pkl'\")\n",
        "\n",
        "    # LSTM\n",
        "    print(\"\\nTraining LSTM...\")\n",
        "    lstm_model = Sequential([\n",
        "        LSTM(64, activation='relu', input_shape=(X_lstm.shape[1], X_lstm.shape[2]), return_sequences=True),\n",
        "        Dropout(0.2),\n",
        "        LSTM(32, activation='relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    lstm_model.compile(optimizer='adam', loss='mse')\n",
        "    for fold, (train_idx, test_idx) in enumerate(tscv.split(X_lstm)):\n",
        "        X_train, X_test = X_lstm[train_idx], X_lstm[test_idx]\n",
        "        y_train, y_test = y_lstm[train_idx], y_lstm[test_idx]\n",
        "        print(f\"LSTM (Fold {fold+1}) - Training...\")\n",
        "        history = lstm_model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
        "        print(f\"LSTM (Fold {fold+1}) - Evaluating...\")\n",
        "        evaluate_model(y_test, lstm_model.predict(X_test, verbose=0), f\"LSTM (Fold {fold+1})\")\n",
        "    lstm_model.save('lstm_model.h5')\n",
        "    print(\"LSTM model saved as 'lstm_model.h5'\")\n",
        "\n",
        "\n",
        "# Example execution - Load preprocessed data and train models\n",
        "# Assuming X, y, X_lstm, y_lstm are available from the preprocessing step\n",
        "try:\n",
        "    X_tabular = pd.read_csv('X_tabular.csv', index_col='DATE_TIME').values\n",
        "    y_tabular = pd.read_csv('y_tabular.csv', index_col='DATE_TIME')['AC_POWER'].values\n",
        "    X_lstm = np.load('X_lstm.npy')\n",
        "    y_lstm = np.load('y_lstm.npy')\n",
        "\n",
        "    print(\"Loaded preprocessed data.\")\n",
        "    train_models(X_tabular, y_tabular, X_lstm, y_lstm)\n",
        "    print(\"\\nModel training completed.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Preprocessed data files not found. Please run the preprocessing step first.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during model training: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYtDNjrmdvww",
        "outputId": "1c10f9b1-30a4-47dc-ac45-0ca537a76ba7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded preprocessed data.\n",
            "\n",
            "Training Linear Regression...\n",
            "Linear Regression (Fold 1) - MAE: 9.0815, RMSE: 15.2792, R¬≤: 0.9987\n",
            "Linear Regression (Fold 2) - MAE: 9.6494, RMSE: 17.5943, R¬≤: 0.9979\n",
            "Linear Regression (Fold 3) - MAE: 9.1952, RMSE: 14.6706, R¬≤: 0.9985\n",
            "Linear Regression (Fold 4) - MAE: 12.1859, RMSE: 26.3501, R¬≤: 0.9950\n",
            "Linear Regression (Fold 5) - MAE: 9.5144, RMSE: 13.7458, R¬≤: 0.9985\n",
            "Linear Regression model saved as 'lr_model.pkl'\n",
            "\n",
            "Training XGBoost...\n",
            "XGBoost (Fold 1) - MAE: 12.9366, RMSE: 23.1294, R¬≤: 0.9971\n",
            "XGBoost (Fold 2) - MAE: 13.4014, RMSE: 25.2174, R¬≤: 0.9957\n",
            "XGBoost (Fold 3) - MAE: 9.9421, RMSE: 17.8425, R¬≤: 0.9977\n",
            "XGBoost (Fold 4) - MAE: 12.2497, RMSE: 30.0470, R¬≤: 0.9935\n",
            "XGBoost (Fold 5) - MAE: 8.2481, RMSE: 16.1258, R¬≤: 0.9980\n",
            "XGBoost model saved as 'xgb_model.pkl'\n",
            "\n",
            "Training LSTM...\n",
            "LSTM (Fold 1) - Training...\n",
            "LSTM (Fold 1) - Evaluating...\n",
            "LSTM (Fold 1) - MAE: 396.3432, RMSE: 502.6345, R¬≤: -0.3725\n",
            "LSTM (Fold 2) - Training...\n",
            "LSTM (Fold 2) - Evaluating...\n",
            "LSTM (Fold 2) - MAE: 334.9453, RMSE: 449.3632, R¬≤: -0.3537\n",
            "LSTM (Fold 3) - Training...\n",
            "LSTM (Fold 3) - Evaluating...\n",
            "LSTM (Fold 3) - MAE: 136.0558, RMSE: 170.0463, R¬≤: 0.7940\n",
            "LSTM (Fold 4) - Training...\n",
            "LSTM (Fold 4) - Evaluating...\n",
            "LSTM (Fold 4) - MAE: 100.1638, RMSE: 143.1315, R¬≤: 0.8531\n",
            "LSTM (Fold 5) - Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM (Fold 5) - Evaluating...\n",
            "LSTM (Fold 5) - MAE: 80.3153, RMSE: 133.5490, R¬≤: 0.8618\n",
            "LSTM model saved as 'lstm_model.h5'\n",
            "\n",
            "Model training completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üìä Model Evaluation & Visualization\n",
        "\n",
        "def evaluate_and_visualize(X_tabular, y_tabular, X_lstm, y_lstm, lr_model, xgb_model, lstm_model):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_tabular, y_tabular, test_size=0.2, shuffle=False)\n",
        "    X_lstm_train, X_lstm_test, y_lstm_train, y_lstm_test = train_test_split(X_lstm, y_lstm, test_size=0.2, shuffle=False)\n",
        "\n",
        "    lr_pred = lr_model.predict(X_test)\n",
        "    xgb_pred = xgb_model.predict(X_test)\n",
        "    lstm_pred = lstm_model.predict(X_lstm_test).ravel()\n",
        "\n",
        "    evaluate_model(y_test, lr_pred, \"Linear Regression\")\n",
        "    evaluate_model(y_test, xgb_pred, \"XGBoost\")\n",
        "    evaluate_model(y_lstm_test, lstm_pred, \"LSTM\")\n",
        "\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.plot(y_test, label='Actual')\n",
        "    plt.plot(lr_pred, label='Linear Regression')\n",
        "    plt.plot(xgb_pred, label='XGBoost')\n",
        "    plt.plot(range(len(lstm_pred)), lstm_pred, label='LSTM')\n",
        "    plt.legend()\n",
        "    plt.title('Actual vs Predicted')\n",
        "    plt.savefig('actual_vs_predicted.png')\n",
        "    plt.close()\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plot_importance(xgb_model, max_num_features=10)\n",
        "    plt.title('XGBoost Feature Importance')\n",
        "    plt.savefig('xgb_feature_importance.png')\n",
        "    plt.close()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IyrXuehIdyIx"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}